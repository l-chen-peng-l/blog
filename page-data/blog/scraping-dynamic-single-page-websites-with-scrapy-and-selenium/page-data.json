{"componentChunkName":"component---src-templates-article-page-js","path":"/blog/scraping-dynamic-single-page-websites-with-scrapy-and-selenium/","webpackCompilationHash":"05993ececeb8f04d6dab","result":{"data":{"markdownRemark":{"id":"4836e76d-16df-5adb-8fc9-e2b7cc4383b2","html":"<p>Last week I was assigned a task of scraping some data from a website, regular stuff no big deal. So, I set up a Scrapy Project, write the spider, and run the project sipping tea. What do I get?! A blank CSV file with no data! I try some more, make changes to the selector, and run it again to no avail. Then I notice that the website is made on Angular JS. Neither <code>beautiful_soup</code> nor <code>Scrapy</code> can scrape dynamic websites. I look up online and find out that only two frameworks that can do so are: <code>Splash</code> and <code>Selenium</code>. I chose <code>Selenium</code>, mainly for two reasons:</p>\n<ul>\n<li>More Python friendly</li>\n<li>More likely to be useful in future projects.</li>\n</ul>\n<p>In brief what we're about to do is, use the webdriver of a browser with the help of Selenium to render the entire page along with the dynamic parts, then scrape it. But before we begin, I'm gonna assume the following:</p>\n<ul>\n<li>This is not a scrapy tutorial for beginners, I'll assume some familiarity</li>\n<li>A dummy page to be scraped, the links that have to be scraped has the class \"ng-binding\"</li>\n<li>A scrapy project has been set up and blank spider script is ready, wherein our code goes.</li>\n</ul>\n<h2>Setting up Geckodriver</h2>\n<p>To begin we need to install, <code>geckodriver</code>, which is webdriver for Firefox web browser. I'm gonna write the instructions for Linux, you can look up the installation for your specific OS.\nFirst, download the latest edition of geckodriver:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/mozilla/geckodriver/releases/download/v0.20.1/geckodriver-v0.20.1-linux64.tar.gz</code></pre></div>\n<p>Extract the file with:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">tar</span> -xvzf geckodriver*</code></pre></div>\n<p>Make it executable:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">chmod</span> +x geckodriver</code></pre></div>\n<p>Make it accessible by command line:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">mv</span> geckodriver /usr/local/bin/</code></pre></div>\n<h2>Writing the Spider</h2>\n<p>In the spider file, lets assume its name is <code>angular.py</code> first we need to import the following:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> scrapy\n<span class=\"token keyword\">import</span> csv\n<span class=\"token keyword\">from</span> selenium <span class=\"token keyword\">import</span> webdriver</code></pre></div>\n<p>Then we need to set up the spider class:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">AngularSpider</span><span class=\"token punctuation\">(</span>scrapy<span class=\"token punctuation\">.</span>Spider<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    name <span class=\"token operator\">=</span> <span class=\"token string\">'angular_spider'</span>\n    start_urls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">'https://www.example.com/?page=1'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'https://www.example.com/?page=2'</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">]</span>    \n    <span class=\"token comment\"># Initalize the webdriver    </span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>driver <span class=\"token operator\">=</span> webdriver<span class=\"token punctuation\">.</span>Firefox<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    \n    <span class=\"token comment\"># Parse through each Start URLs</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">start_requests</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> url <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>start_urls<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">yield</span> scrapy<span class=\"token punctuation\">.</span>Request<span class=\"token punctuation\">(</span>url<span class=\"token operator\">=</span>url<span class=\"token punctuation\">,</span> callback<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">)</span>    \n    \n\n   <span class=\"token comment\"># Parse function: Scrape the webpage and store it</span>\n   <span class=\"token keyword\">def</span> <span class=\"token function\">parse</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> response<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n       <span class=\"token keyword\">pass</span>   </code></pre></div>\n<p>The real magic happens in the parse function, here we'll write the selector for the data, and the output in a CSV file:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n    \n    <span class=\"token comment\"># Parse function: Scrape the webpage and store it</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">parse</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> response<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>driver<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span>url<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Output filename</span>\n        filename <span class=\"token operator\">=</span> <span class=\"token string\">\"angular_data.csv\"</span>\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> <span class=\"token string\">'a+'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n            writer <span class=\"token operator\">=</span> csv<span class=\"token punctuation\">.</span>writer<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n            <span class=\"token comment\"># Selector for all the names from the link with class 'ng-binding'</span>\n            names <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>driver<span class=\"token punctuation\">.</span>find_elements_by_css_selector<span class=\"token punctuation\">(</span><span class=\"token string\">\"a.ng-binding\"</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">for</span> name <span class=\"token keyword\">in</span> names<span class=\"token punctuation\">:</span>\n                title <span class=\"token operator\">=</span> name<span class=\"token punctuation\">.</span>text\n                writer<span class=\"token punctuation\">.</span>writerow<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>title<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token string\">'Saved file %s'</span> <span class=\"token operator\">%</span> filename<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Now when you run this using:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">scrapy crawl angular_spider</code></pre></div>\n<p>You'll notice a browser opens up and the page is loaded, and when the scraping is complete you can open the CSV file and see the data.</p>","fields":{"slug":"/blog/scraping-dynamic-single-page-websites-with-scrapy-and-selenium/"},"frontmatter":{"date":"May 04, 2018","title":"Scraping Dynamic Websites (Angular, React etc) with Scrapy and Selenium","cover":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAABAABBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHmoJkMiy//xAAZEAEAAgMAAAAAAAAAAAAAAAABAAIQERP/2gAIAQEAAQUCrUnMIVCbz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABoQAAICAwAAAAAAAAAAAAAAAAABAiAxMjP/2gAIAQEABj8CydEjeNP/xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhYTFRkf/aAAgBAQABPyFe3UqCayQjL+zCLm4UnE//2gAMAwEAAgADAAAAEDfv/8QAGBEAAwEBAAAAAAAAAAAAAAAAABEhAVH/2gAIAQMBAT8Qio84f//EABcRAAMBAAAAAAAAAAAAAAAAAAARIVH/2gAIAQIBAT8QrLp//8QAHBABAQACAwEBAAAAAAAAAAAAAREAITFBUaHB/9oACAEBAAE/EIYhrtMK5lFFHx5xUOLbV+Zo9uS3aepzjsfvP//Z","aspectRatio":1.4336917562724014,"src":"/blog/static/aac21e26cda31792d1fde17949169fc5/1511b/scraping_dynamic_webapps.jpg","srcSet":"/blog/static/aac21e26cda31792d1fde17949169fc5/79e64/scraping_dynamic_webapps.jpg 269w,\n/blog/static/aac21e26cda31792d1fde17949169fc5/b1729/scraping_dynamic_webapps.jpg 538w,\n/blog/static/aac21e26cda31792d1fde17949169fc5/1511b/scraping_dynamic_webapps.jpg 1075w,\n/blog/static/aac21e26cda31792d1fde17949169fc5/57d19/scraping_dynamic_webapps.jpg 1613w,\n/blog/static/aac21e26cda31792d1fde17949169fc5/ede7d/scraping_dynamic_webapps.jpg 2150w,\n/blog/static/aac21e26cda31792d1fde17949169fc5/38511/scraping_dynamic_webapps.jpg 4000w","sizes":"(max-width: 1075px) 100vw, 1075px"}},"publicURL":"/blog/static/scraping_dynamic_webapps-aac21e26cda31792d1fde17949169fc5.jpg"},"meta_title":"Scraping Dynamic Websites (Angular, React etc) with Scrapy and Selenium","meta_description":"Scraping websites made with Javascript frameworks like Angular and React is not possible with Scrapy or Beautiful Soup, learn to do so with the added help of Selenium.","tags":["Scrapy","Selenium","Python","Scraping"]}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"id":"4836e76d-16df-5adb-8fc9-e2b7cc4383b2"}}}